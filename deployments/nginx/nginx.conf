events {
    # Max simultaneous connections per Nginx worker process.
    worker_connections 1024;
}

http {

    # LOAD BALANCING: Define target groups for the API replicas
    #
    # - Nginx does NOT talk to "containers by name".
    # - It talks to IP:port targets.
    # - Docker Compose provides an internal DNS server for the compose network.
    # - When we scale `api-v1` to 3 replicas (via 'docker compose up..  --scale api-v1=3...'), 
    #   Docker DNS resolves `api-v1` to multiple IPs (one per replica).
    # - Nginx uses those resolved IPs as the actual backend targets and distributes requests across them.
    #
    # upstream = a named backend "pool" (a group of servers Nginx can proxy to)
    # Define upstream targets by docker-compose *service name* (Compose provides DNS for these names)
    # Both APIs listen on port 8000 inside their containers
    upstream api_v1_pool {
        # Key idea:
        # - `api-v1` is the *compose service name* (internal DNS entry on the compose network).
        # - With `--scale api-v1=3`, that DNS name points to multiple replica IPs.
        # - Nginx will send requests to those replica IPs (not always the same one).        
        server api-v1:8000;

        # Load balancing strategy:
        # - Default is round-robin (cycle through available backend addresses).
        # - least_conn: send to the backend with the fewest active connections (better under uneven load).
        # - ip_hash: sticky-ish sessions based on client IP (same client tends to hit same backend).
        # Note: for this exam, default round-robin is usually sufficient.
        # least_conn;
        # ip_hash;   
    }

    # Separate upstream for v2 (usually only 1 instance for A/B / debug)
    upstream api_v2_single {
        server api-v2:8000;
    }

    # HTTP: redirect everything to HTTPS
    server {
        # Nginx listens on port 80 *inside the container*.
        # Docker publishes it to the host via compose `ports: - "8080:80"`.           
        listen 80;
        server_name localhost;

        return 301 https://$host$request_uri;
    }

    # HTTPS: terminate TLS and proxy to the API pool
    server {     
        listen 443 ssl;
        server_name localhost;

        # SSL SETUP
        ssl_certificate /etc/nginx/certs/nginx.crt;
        ssl_certificate_key /etc/nginx/certs/nginx.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;


        # Baseline routing:
        # - For now, forward /predict to v1 by default.
        # - v2 will be used later for A/B testing based on request headers.
        location /predict {
            # Basic Auth: protect this endpoint with username/password
            auth_basic "API Access Protected"; # Message displayed to the user
            auth_basic_user_file /etc/nginx/.htpasswd; # Path to the .htpasswd file in the container

            # Reverse Proxcyying: Redirect requests to the upstream group
            # - Client hits Nginx (/predict)
            # - Nginx forwards that request to one backend/api-service chosen from `api_v1_pool`
            # - With 3 replicas, successive requests should fan out across api-v1-1/2/3            
            proxy_pass http://api_v1_pool;

            # Preserve original request metadata for the backend:
            # - Host: what the client used (useful for debugging / virtual hosts later)
            # - X-Real-IP: the client IP as seen by Nginx
            # - X-Forwarded-For: a chain of client/proxy IPs (standard proxy header)
            # - X-Forwarded-Proto: http/https (important once TLS is added)
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}